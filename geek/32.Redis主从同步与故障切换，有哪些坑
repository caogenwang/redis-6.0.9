Redis的主从同步机制不仅可以让从库服务更多的读请求，分担主库的压力，而且还能在主库发生故障时，进行主从库切换，提供高可靠服务

我就向你介绍3个坑，分别是主从数据不一致、读到过期数据，以及配置项设置得不合理从而导致服务挂掉.

1. 主从数据不一致:主从数据不一致，就是指客户端从从库中读取到的值和主库中的最新值并不一致.
    那为啥会出现这个坑呢？其实这是因为主从库间的命令复制是异步进行的。

    一方面，主从库间的网络可能会有传输延迟，所以从库不能及时地收到主库发送的命令.
    一方面，即使从库及时收到了主库的命令，但是，也可能会因为正在处理其它复杂度高的命令（例如集合操作命令）而阻塞

    解决方法：
    首先，在硬件环境配置方面，我们要尽量保证主从库间的网络连接状况良好
    另外，我们还可以开发一个外部程序来监控主从库间的复制进度。

2.读取过期数据：
    我们在使用Redis主从集群时，有时会读到过期数据。例如，数据X的过期时间是202010240900，
    但是客户端在202010240910时，仍然可以从从库中读到数据X。一个数据过期后，应该是被删除的，
    客户端不能再读取到该数据，但是，Redis为什么还能在从库中读到过期的数据呢？

    这是由Redis的过期数据删除策略引起的

    Redis同时使用了两种策略来删除过期的数据，分别是惰性删除策略和定期删除策略。

    定期删除策略是指，Redis每隔一段时间（默认100ms），就会随机选出一定数量的数据

    主从库之间因为同步的时间问题，导致主库和从库的数据不一致
    在业务应用中使用EXPIREAT/PEXPIREAT命令，把数据的过期时间设置为具体的时间点，避免读到过期数据

    主从数据不一致。Redis采用的是异步复制，所以无法实现强一致性保证（主从数据时时刻刻保持一致），
    数据不一致是难以避免的。我给你提供了应对方法：保证良好网络环境，以及使用程序监控从库复制进度，
    一旦从库复制进度超过阈值，不让客户端连接从库。
    对于读到过期数据，这是可以提前规避的，一个方法是，使用Redis 3.2及以上版本；
    另外，你也可以使用EXPIREAT/PEXPIREAT命令设置过期时间，避免从库上的数据过期时间滞后。
    不过，这里有个地方需要注意下，因为EXPIREAT/PEXPIREAT设置的是时间点，
    所以，主从节点上的时钟要保持一致，具体的做法是，让主从节点和相同的NTP服务器（时间服务器）
    进行时钟同步。

3. 不合理配置项导致的服务挂掉
    1. protected-mode 配置项
        这个配置项的作用是限定哨兵实例能否被其他服务器访问。当这个配置项设置为yes时，哨兵实例只能在部署的服务器本地进行访问。
        当设置为no时，其他服务器也可以访问这个哨兵实例。

        如果protected-mode被设置为yes，而其余哨兵实例部署在其它服务器，那么，这些哨兵实例间就无法通信。
        要注意将protected-mode 配置项设置为no，并且将bind配置项设置为其它哨兵实例的IP地址。
        这样一来，只有在bind中设置了IP地址的哨兵，才可以访问当前实例，既保证了实例间能够通信进行主从切换，
        也保证了哨兵的安全性。

        protected-mode no
        bind 192.168.10.3 192.168.10.4 192.168.10.5

    2. cluster-node-timeout配置项
        这个配置项设置了Redis Cluster中实例响应心跳消息的超时时间。
        如果执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例心跳超时，
        从而可能导致整个集群挂掉。
        所以，我建议你将cluster-node-timeout调大些（例如10到20秒）

问题:
把 slave-read-only 设置为 no，让从库也能直接删除数据，以此来避免读到过期数据，这种方案是否可行？
我个人觉得这个问题有些歧义，因为尽管把 slave-read-only 设置为 no，其实 slave 也不会主动过期删除从
 master 同步过来的数据的。
我猜老师想问的应该是：假设让 slave 也可以自动删除过期数据，是否可以保证主从库的一致性？
其实这样也无法保证，例如以下场景：

1、主从同步存在网络延迟。例如 master 先执行 SET key 1 10，这个 key 同步到了 slave，
    此时 key 在主从库都是 10s 后过期，之后这个 key 还剩 1s 过期时，master 又执行了 expire key 60，
    重设这个 key 的过期时间。但 expire 命令向 slave 同步时，发生了网络延迟并且超过了 1s，
    如果 slave 可以自动删除过期 key，那么这个 key 正好达到过期时间，就会被 slave 删除了，
    之后 slave 再收到 expire 命令时，执行会失败。最后的结果是这个 key 在 slave 上丢失了，
    主从库发生了不一致。

2、主从机器时钟不一致。同样 master 执行 SET key 1 10，然后把这个 key 同步到 slave，
但是此时 slave 机器时钟如果发生跳跃，优先把这个 key 过期删除了，也会发生上面说的不一致问题。
所以 Redis 为了保证主从同步的一致性，不会让 slave 自动删除过期 key，而只在 master 删除过期 key，
之后 master 会向 slave 发送一个 DEL，slave 再把这个 key 删除掉，
这种方式可以解决主从网络延迟和机器时钟不一致带来的影响。

    再解释一下 slave-read-only 的作用，它主要用来控制 slave 是否可写，但是否主动删除过期 key，根据 Redis 版本不同，执行逻辑也不同。
    1、如果版本低于 Redis 4.0，slave-read-only 设置为 no，此时 slave 允许写入数据，但如果 key 设置了过期时间，那么这个 key 过期后，虽然在 slave 上查询不到了，但并不会在内存中删除，这些过期 key 会一直占着 Redis 内存无法释放。
    2、Redis 4.0 版本解决了上述问题，在 slave 写入带过期时间的 key，slave 会记下这些 key，并且在后台定时检测这些 key 是否已过期，过期后从内存中删除。
    但是请注意，这 2 种情况，slave 都不会主动删除由 *master 同步过来带有过期时间的 key*。也就是 master 带有过期时间的 key，什么时候删除由 master 自己维护，slave 不会介入。如果 slave 设置了 slave-read-only = no，而且是 4.0+ 版本，slave 也只维护直接向自己写入 的带有过期的 key，过期时只删除这些 key。
    另外，我还能想到的主从同步的 2 个问题:
    1、主从库设置的 maxmemory 不同，如果 slave 比 master 小，那么 slave 内存就会优先达到 maxmemroy，然后开始淘汰数据，此时主从库也会产生不一致。
    2、如果主从同步的 client-output-buffer-limit 设置过小，并且 master 数据量很大，主从全量同步时可能会导致 buffer 溢出，溢出后主从全量同步就会失败。如果主从集群配置了哨兵，那么哨兵会让 slave 继续向 master 发起全量同步请求，然后 buffer 又溢出同步失败，如此反复，会形成复制风暴，这会浪费 master 大量的 CPU、内存、带宽资源，也会让 master 产生阻塞的风险。